<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Hyun Seok Seong</title>
  
  <meta name="author" content="Hyun Seok Seong">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/skku_icon.jpeg">

  <script type="text/javascript">

    function display(id) {
      var traget = document.getElementById(id);
      if (traget.style.display == "none") {
        traget.style.display = "";
      } else {
        traget.style.display = "none";
      }
    }  
  </script>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Hyun Seok Seong</name>
              </p>
              <p> I am a Ph.D. candidate in the
                <a href="https://sites.google.com/site/vclabskku/">Visual Computing Lab (VCLab)</a> at Sungkyunkwan University, supervised by Prof.
                <a href="https://sites.google.com/site/jaepilheo">Jae-Pil Heo</a>.
<!--                <a href="https://www.hku.hk/">The University of Hong Kong</a>, fortunately supervised by Prof. <a href="https://hszhao.github.io/">Hengshuang Zhao</a>. -->
              </p>
<!--              <p> I received my Bachelor's degree from Sungkyunkwan University.-->
<!--              </p>-->
              <p>
<!--                v1: My research interests include various tasks in machine learning-->
<!--                  and computer vision, with a particular focus on object categorization and semantic segmentation. Recently my interest has been-->
<!--                  in addressing segmentation tasks with limited labeled data, with a specific focus on unsupervised semantic segmentation which-->
<!--                  is a key task for solving real-world problems.-->
<!--                v2: My research interests include various tasks in machine learning-->
<!--                  and computer vision, with a particular focus on image segmentation and grounding with limited labeled data.-->
<!--                  Recently, my interest has been in unsupervised semantic segmentation and weakly-supervised affordance grounding.-->
<!--                    v3: My research primarily focuses on representation learning for image segmentation and grounding under limited supervision.-->
<!--                    In addition, I am broadly interested in multi-modal learning, video understanding, domain generalization, few-shot learning, and long-tailed recognition.-->
                    My research focuses on representation learning for image and video understanding under limited supervision, including multi-modal learning.
                    More broadly, I have extensive experience addressing real-world challenges such as domain generalization, few-shot & open-set & long-tailed recognition.
              </p>
              <p style="text-align:center">
                <a href="mailto:gustjrdl95@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=ZGbTICYAAAAJ&hl">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/hynnsk">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/hyun-seok-seong-7b4a70242">LinkedIn</a> &nbsp/&nbsp
                <a href="./images/CV_of_Hyun_Seok_Seong_20260221.pdf">CV</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/hyunseok_3_4.png"><img style="width:80%;max-width:80%" alt="profile photo" src="images/hyunseok_3_4.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
<!--        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>-->
<!--          <tr>-->
<!--          <td style="padding:20px;width:100%;vertical-align:middle">-->
<!--            <heading>News</heading>-->
<!--            <p> <strong>2024-06:</strong> <a href="https://depth-anything-v2.github.io/">Depth Anything V2</a> is released. </p>-->
<!--            <p> <strong>2024-02:</strong> <a href="https://depth-anything.github.io/">Depth Anything</a> is accepted by <em>CVPR</em> 2024. </p>-->
<!--            <p> <strong>2023-12:</strong> I am awarded the <em>NeurIPS</em> 2023 Top Reviewer. </p>-->
<!--            <p> <strong>2023-09:</strong> One paper on generative perception is accepted by <em>NeurIPS</em> 2023. </p>-->
<!--            <p> <strong>2023-09:</strong> I start at HKU as a PhD student.</p>-->
<!--            <p> <strong>2023-07:</strong> Two papers on semi-supervised learning and semantic segmentation are accepted by <em>ICCV</em> 2023. </p>-->
<!--	          <p> <strong>2023-02:</strong> Two papers on semi-supervised semantic segmentation are accepted by <em>CVPR</em> 2023. </p>-->
<!--            <p> <strong>2023-02:</strong> I am awarded the HKU Presidential PhD Scholarship. </p>-->
<!--            <a onclick="return display('old_news');"> &#45;&#45;&#45;&#45; show more &#45;&#45;&#45;&#45;</a>-->
<!--            <div id="old_news" style="display: none;">-->
<!--              <p> <strong>2022-03:</strong> One paper on semi-supervised semantic segmentation is accepted by <em>CVPR</em> 2022. </p>-->
<!--              <p> <strong>2021-10:</strong> I am awarded the National Scholarship. </p>-->
<!--              <p> <strong>2021-07:</strong> One paper on few-shot segmentation is accepted by <em>ICCV</em> 2021 as an Oral presentation. </p>-->
<!--            </div>-->

<!--          </td>-->
<!--        </tr>-->

<!------------------------------------------------------------------------------------------------------------------>


<!------------------------------------------------------------------------------------------------------------------>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Publications</heading>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



        <tr>
          <td style="padding:20px;width:30%;vertical-align:middle">
            <img src='images/Slotcurri.png' alt="game" width="180" style="border-style: none">
          </td>
          <td style="padding:20px;width:70%;vertical-align:middle">
            <a >
              <papertitle>Reconstruction-Guided Slot Curriculum: Addressing Object Over-Fragmentation in Video Object-Centric Learning</papertitle>
            </a>
            <br>
            WonJun Moon, <strong>Hyun Seok Seong</strong>, and Jae-Pil Heo
            <br>
            <em>Computer Vision and Pattern Recognition  (<b>CVPR</b>)</em>, 2026
            <br>
<!--            <a href="https://arxiv.org/abs/2508.07877">Arxiv</a> /-->
<!--            <a href="https://github.com/hynnsk/SelectiveCL">Code</a>-->
          </td>
        </tr>


        <tr>
          <td style="padding:20px;width:30%;vertical-align:middle">
            <img src='images/GLACLIP.png' alt="game" width="180" style="border-style: none">
          </td>
          <td style="padding:20px;width:70%;vertical-align:middle">
            <a >
              <papertitle>Looking Beyond the Window: Global-Local Aligned CLIP for Training-free Open-Vocabulary Semantic Segmentation</papertitle>
            </a>
            <br>
            ByeongCheol Lee, <strong>Hyun Seok Seong</strong>, Sangeek Hyun, Gilhan Park, WonJun Moon, and Jae-Pil Heo
            <br>
            <em>Computer Vision and Pattern Recognition  (<b>CVPR</b>)</em>, 2026
            <br>
<!--            <a href="https://arxiv.org/abs/2508.07877">Arxiv</a> /-->
<!--            <a href="https://github.com/hynnsk/SelectiveCL">Code</a>-->
          </td>
        </tr>



        <tr>
          <td style="padding:20px;width:30%;vertical-align:middle">
            <img src='images/SRL.png' alt="game" width="180" style="border-style: none">
          </td>
          <td style="padding:20px;width:70%;vertical-align:middle">
            <a >
              <papertitle>From Vicious to Virtuous Cycles: Synergistic Representation Learning for Video Object-Centric Learning</papertitle>
            </a>
            <br>
            <strong>Hyun Seok Seong*</strong>, WonJun Moon*, and Jae-Pil Heo (*: equal contribution)
            <br>
            <em>International Conference on Learning Representations (<b>ICLR</b>)</em>, 2026
            <br>
<!--            <a href="https://arxiv.org/abs/2508.07877">Arxiv</a> /-->
<!--            <a href="https://github.com/hynnsk/SelectiveCL">Code</a>-->
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:30%;vertical-align:middle">
            <img src='images/SCL.png' alt="game" width="180" style="border-style: none">
          </td>
          <td style="padding:20px;width:70%;vertical-align:middle">
            <a >
              <papertitle>Selective Contrastive Learning for Weakly Supervised Affordance Grounding</papertitle>
            </a>
            <br>
            WonJun Moon*, <strong>Hyun Seok Seong*</strong>, and Jae-Pil Heo (*: equal contribution)
            <br>
            <em>International Conference on Computer Vision (<b>ICCV</b>)</em>, 2025
            <br>
            <a href="https://arxiv.org/abs/2508.07877">Arxiv</a> /
            <a href="https://github.com/hynnsk/SelectiveCL">Code</a>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:30%;vertical-align:middle">
            <img src='images/Team.png' alt="game" width="180" style="border-style: none">
          </td>
          <td style="padding:20px;width:70%;vertical-align:middle">
            <a >
              <papertitle>Temporal Alignment-Free Video Matching for Few-shot Action Recognition</papertitle>
            </a>
            <br>
            SuBeen Lee, WonJun Moon, <strong>Hyun Seok Seong</strong>, and Jae-Pil Heo
            <br>
            <em>Computer Vision and Pattern Recognition  (<b>CVPR</b>)</em>, 2025 <b>(Oral presentation)</b>
            <br>
            <a href="https://arxiv.org/abs/2504.05956">Arxiv</a> /
            <a href="https://github.com/leesb7426/TEAM">Code</a>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:30%;vertical-align:middle">
            <img src='images/FCP.png' alt="game" width="180" style="border-style: none">
          </td>
          <td style="padding:20px;width:70%;vertical-align:middle">
            <a >
              <papertitle>Foreground-Covering Prototype Generation and Matching for SAM-Aided Few-Shot Segmentation</papertitle>
            </a>
            <br>
            Suho Park*, SuBeen Lee*, <strong>Hyun Seok Seong</strong>, Jaejoon Yoo, and Jae-Pil Heo (*: equal contribution)
            <br>
            <em>AAAI Conference on Artificial Intelligence (<b>AAAI</b>)</em>, 2025
            <br>
            <a href="https://arxiv.org/abs/2501.00752">Arxiv</a> /
            <a href="https://github.com/SuhoPark0706/FCP">Code</a>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:30%;vertical-align:middle">
            <img src='images/ppap.png' alt="game" width="180" style="border-style: none">
          </td>
          <td style="padding:20px;width:70%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2407.12463">
              <papertitle>Progressive Proxy Anchor Propagation for Unsupervised Semantic Segmentation</papertitle>
            </a>
            <br>
            <strong>Hyun Seok Seong</strong>, WonJun Moon, SuBeen Lee, and Jae-Pil Heo
            <br>
            <em>European Conference on Computer Vision (<b>ECCV</b>)</em>, 2024
            <br>
            <a href="https://arxiv.org/abs/2407.12463">Arxiv</a> /
            <a href="https://github.com/hynnsk/PPAP">Code</a>
          </td>
        </tr>

                <tr>
          <td style="padding:20px;width:30%;vertical-align:middle">
            <img src='images/tdmiam.png' alt="game" width="180" style="border-style: none">
          </td>
          <td style="padding:20px;width:70%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2308.00093">
              <papertitle>Task-Oriented Channel Attention for Fine-Grained Few-Shot Classification</papertitle>
            </a>
            <br>
            SuBeen Lee, WonJun Moon, <strong>Hyun Seok Seong</strong>, and Jae-Pil Heo
            <br>
            <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>)</em>, 2024
            <br>
            <a href="https://arxiv.org/abs/2308.00093">Arxiv</a> /
            <a href="https://github.com/leesb7426/CVPR2022-Task-Discrepancy-Maximization-for-Fine-grained-Few-Shot-Classification">Code</a>
          </td>
        </tr>


        <tr>
          <td style="padding:20px;width:30%;vertical-align:middle">
            <img src='images/tbs.png' alt="game" width="180" style="border-style: none">
          </td>
          <td style="padding:20px;width:70%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2312.15894">
              <papertitle>Task-disruptive Background Suppression for Few-Shot Segmentation</papertitle>
            </a>
            <br>
            Suho Park, SuBeen Lee, Sangeek Hyun, <strong>Hyun Seok Seong</strong>, and Jae-Pil Heo
            <br>
            <em>AAAI Conference on Artificial Intelligence (<b>AAAI</b>)</em>, 2024
            <br>
            <a href="https://arxiv.org/abs/2312.15894">Arxiv</a> /
            <a href="https://ojs.aaai.org/index.php/AAAI/article/view/28242/28479">Paper</a> /
            <a href="https://github.com/suhopark0706/tbsnet">Code</a>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:30%;vertical-align:middle">
            <img src='images/hp.png' alt="game" width="180" style="border-style: none">
          </td>
          <td style="padding:20px;width:70%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2303.15014">
              <papertitle>Leveraging Hidden Positives for Unsupervised Semantic Segmentation</papertitle>
            </a>
            <br>
            <strong>Hyun Seok Seong</strong>, WonJun Moon, SuBeen Lee, and Jae-Pil Heo
            <br>
            <em>Computer Vision and Pattern Recognition (<b>CVPR</b>)</em>, 2023
            <br>
            <a href="https://arxiv.org/abs/2303.15014">Arxiv</a> /
            <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Seong_Leveraging_Hidden_Positives_for_Unsupervised_Semantic_Segmentation_CVPR_2023_paper.pdf">Paper</a> /
            <a href="https://github.com/hynnsk/HP">Code</a>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:30%;vertical-align:middle">
            <img src='images/move.png' alt="game" width="180" style="border-style: none">
          </td>
          <td style="padding:20px;width:70%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2211.13471">
              <papertitle>Minority-Oriented Vicinity Expansion with Attentive Aggregation for Video Long-Tailed Recognition</papertitle>
            </a>
            <br>
            WonJun Moon, <strong>Hyun Seok Seong</strong>, and Jae-Pil Heo
            <br>
            <em>AAAI Conference on Artificial Intelligence (<b>AAAI</b>)</em>, 2023 <b>(Oral presentation)</b>
            <br>
            <a href="https://arxiv.org/abs/2211.13471">Arxiv</a> /
            <a href="https://ojs.aaai.org/index.php/AAAI/article/view/25284/25056">Paper</a> /
            <a href="https://github.com/wjun0830/MOVE">Code</a>
          </td>
        </tr>


        <tr>
          <td style="padding:20px;width:30%;vertical-align:middle">
            <img src='images/tcx.png' alt="game" width="180" style="border-style: none">
          </td>
          <td style="padding:20px;width:70%;vertical-align:middle">
            <a href="https://www.sciencedirect.com/science/article/pii/S0167865523002787">
              <papertitle>TCX: Texture and channel swappings for domain generalization</papertitle>
            </a>
            <br>
            Jaehyun Choi, <strong>Hyun Seok Seong</strong>, Sanguk Park, and Jae-Pil Heo
            <br>
            <em>Pattern Recognition Letters</em>, 2023
            <br>
            <a href="https://www.sciencedirect.com/science/article/pii/S0167865523002787">Paper</a>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:30%;vertical-align:middle">
            <img src='images/dias.png' alt="game" width="180" style="border-style: none">
          </td>
          <td style="padding:20px;width:70%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2207.10024">
              <papertitle>Difficulty-Aware Simulator for Open Set Recognition</papertitle>
            </a>
            <br>
            WonJun Moon, Junho Park, <strong>Hyun Seok Seong</strong>, Cheol-Ho Cho, and Jae-Pil Heo
            <br>
            <em>European Conference on Computer Vision (<b>ECCV</b>)</em>, 2022
            <br>
            <a href="https://arxiv.org/abs/2207.10024">Arxiv</a> /
            <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136850360.pdf">Paper</a> /
            <a href="https://github.com/wjun0830/Difficulty-Aware-Simulator">Code</a>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:30%;vertical-align:middle">
            <img src='images/pge.png' alt="game" width="180" style="border-style: none">
          </td>
          <td style="padding:20px;width:70%;vertical-align:middle">
            <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9967985&tag=1">
              <papertitle>Pivot-Guided Embedding for Domain Generalization</papertitle>
            </a>
            <br>
            <strong>Hyun Seok Seong</strong>, Jaehyun Choi, Woojin Jeong, and Jae-Pil Heo
            <br>
            <em>IEEE Access</em>, 2022
            <br>
            <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9967985&tag=1">Paper</a> /
            <a href="https://github.com/hynnsk/PGE_DG">Code</a>
          </td>
        </tr>

<!------------------------------------------------------------------------------------------------------------------>
<!------------------------------------------------------------------------------------------------------------------>

      </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Education</heading>
              <p>
                <li><b>Sungkyunkwan University (SKKU), South Korea</b></li>
                &nbsp &nbsp &nbsp &nbsp Integrated M.S. and Ph.D., Artificial Intelligence </br>
                &nbsp &nbsp &nbsp &nbsp Sep. 2019 - present
              </p>
              <p>
                <li><b>Sungkyunkwan University (SKKU), South Korea</b></li>
                &nbsp &nbsp &nbsp &nbsp B.S., Electronic and Electrical Engineering </br>
                &nbsp &nbsp &nbsp &nbsp Mar. 2013 - Feb. 2019
              </p>
            </td>
          </tr>
        </tbody></table>

<!--        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>-->
<!--          <tr>-->
<!--            <td style="padding:20px;width:100%;vertical-align:middle">-->
<!--              <heading>Honors</heading>-->
<!--              <p>-->
<!--                <b>NeurIPS Top Reviewer</b>, NeurIPS, 2023-->
<!--              </p>-->
<!--              <p>-->
<!--                <b>HKU Presidential PhD Scholarship</b>, The University of Hong Kong, 2023-2027-->
<!--              </p>-->
<!--              <p>-->
<!--                <b>Tencent Scholarship</b>, Nanjing University, 2022-->
<!--              </p>-->
<!--              <p>-->
<!--                <b>First Prize Scholarship for Postgraduate Students</b>, Nanjing University, 2020-2022-->
<!--              </p>-->
<!--              <p>-->
<!--              <b>National Scholarship</b>, Ministry of Education of P.R. China, 2021-->
<!--              </p>-->
<!--              <p>-->
<!--                <b>First Prize of Excellent Undergraduate Thesis</b>, Nanjing University, 2020-->
<!--              </p>-->
<!--              <p>-->
<!--                <b>MICCAI Undergraduate Student Travel Award</b>, MICCAI, 2019-->
<!--              </p>-->
<!--            </td>-->
<!--          </tr>-->
<!--        </tbody></table>-->

<!--        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>-->
<!--          <tr>-->
<!--            <td style="padding:20px;width:100%;vertical-align:middle">-->
<!--              <heading>Academic Services</heading>-->
<!--              <p>-->
<!--                Conference reviewer: CVPR, ICCV, ECCV, NeurIPS, ICLR, ICML, etc.-->
<!--              </p>-->

<!--              <p>-->
<!--                Journal reviewer: TIP, TNNLS, TCSVT, TGRS, etc.-->
<!--              </p>-->
<!--              -->
<!--            </td>-->
<!--          </tr>-->
<!--        </tbody></table>-->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <br>
                <a href="https://jonbarron.info/">Website Template</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
